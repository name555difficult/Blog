# Density-invariant Features for Distant Point Cloud Registration

**2023 ICCV**

> ***Quan Liu, Hongzi Zhu, Yunsong Zhou, Hongyang Li, Shan Chang, Minyi Guo\***; Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023, pp. 18215-18225

- paper: [[2307.09788\] Density-invariant Features for Distant Point Cloud Registration (arxiv.org)](https://arxiv.org/abs/2307.09788)
- code: [liuQuan98/GCL: [ICCV 23\] Density-invariant Features for Distant Point Cloud Registration (github.com)](https://github.com/liuQuan98/GCL)

![image-20231005001257374](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005001521551-2078833713.png)

## Idea

é¢å‘outdoor LiDARç‚¹äº‘ï¼Œåˆ©ç”¨multiple point clouds sample set(in the same spatial location), åŸºäºGroup-wise Contrastive Learningæ–¹æ³•ï¼Œåº”ç”¨dense feature extractorï¼ˆFCGF, KPConvâ€¦â€¦ï¼‰ï¼Œæå–density-invariant geometric featuresï¼Œè§£å†³è¿œè·ç¦»æ¿€å…‰é›·è¾¾ç‚¹äº‘é…å‡†(distant outdoor LiDAR point cloud registration)ä»»åŠ¡ã€‚

> distant outdoor LiDAR point cloud registrationçš„éš¾ç‚¹åœ¨äºéšç€ä¸LiDARé—´éš”è·ç¦»çš„æ‰©å¤§ï¼Œä¸åŒç©ºé—´ä½ç½®çš„ç‚¹äº‘å¯†åº¦ä¼šç¨‹äºŒæ¬¡æ›²çº¿æ€§è´¨ä¸‹é™ã€‚è¿™ä¼šé€ æˆä¸åŒç‚¹äº‘é‡å åŒºåŸŸç‚¹äº‘å¯†åº¦ä¸åŒï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•å¯¹äºè¯¥ç‰¹æ€§æ¯”è¾ƒæ•æ„Ÿï¼Œå…¶é…å‡†æ€§èƒ½ä¼šå‘ç”Ÿä¸‹é™ï¼Œä¹Ÿå°±æ˜¯density-mismatch problemã€‚

å›é¡¾ä»¥å‰çš„feature-basedå¯¹æ¯”å­¦ä¹ é…å‡†æ–¹æ³•ï¼Œ**æ¯ä¸€ä¸ªbatchéƒ½æ˜¯ä¸€å¯¹æ­£æ ·æœ¬å¾…é…å‡†ç‚¹äº‘** ï¼Œç„¶åå–æ¨ç†å‡ºå„å…³é”®ç‚¹æ­£æ ·æœ¬å¯¹çš„similar feature descriptorã€‚æ ¹æ®æ–‡çŒ®[^1] ï¼Œè¿™ä¹ˆåšèƒ½å¤Ÿ**æ”¶æ•›çš„å‰ææ˜¯é‡å åŒºåŸŸç‚¹äº‘æ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒ** ï¼Œç®€å•æ¥è¯´å°±æ˜¯å¯†åº¦å’Œå½¢çŠ¶è¿‘ä¼¼ä¸€è‡´ã€‚ä½†æ˜¯æ˜¾ç„¶è¿™æ ·è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹**æ— æ³•è§£å†³density-mismatch problem** ã€‚å®éªŒè¡¨æ˜ï¼Œæ— è®ºæ˜¯å¯†åº¦ç›¸å…³æ–¹æ³•(e.g. voxelization) or å¯†åº¦è‡ªé€‚åº”æ–¹æ³•éƒ½ä¸èƒ½å¾ˆå¥½çš„é…å‡†distant outdoor point cloud.

ä½œè€…æå‡ºçš„æ–¹æ³•ç®€å•æ¥è¯´å°±æ˜¯ï¼šæ—¢ç„¶è®­ç»ƒæ—¶ä¸€å¯¹æ­£æ ·æœ¬è¾¾ä¸åˆ°ï¼Œé‚£æˆ‘å°±å¤šç”¨äº›æ­£æ ·æœ¬ï¼Œç”¨ä¸€ç»„é«˜overlapçš„æ­£æ ·æœ¬å¾…é…å‡†ç‚¹äº‘æ¥è¿›group contrastive learningï¼Œé€šè¿‡è¿™æ ·æ•°æ®å¢å¹¿çš„æ–¹å¼æ¥å®ç°density-invariant featureæå–ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå…‹æœdensity-mismatché—®é¢˜ã€‚

>  åŸæ–‡ï¼š**A large enough positive group can better approximate the underlying feature distribution** .

![image-20231005113435198](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224048189-2036930272.png)

## Contribution

1. ä»ç†è®ºä¸Šåˆ†æäº†distant point clouds registration çš„å›°éš¾ï¼Œæå‡ºæ„å»ºæ›´å¤šçš„ *i.i.d* (independently and identically distributed) positive samples æ˜¯è®­ç»ƒå‡ºdensity-invariant feature descriptorçš„å…³é”®;
2. åŸºäºgroup-wise contrastive learningï¼Œæå‡ºæœ‰æ•ˆçš„density-invariant feature descriptor è®­ç»ƒæ–¹æ¡ˆå’Œç›¸åº”çš„lossï¼›
3. åœ¨KITTIå’ŒnuScenesçš„è¿œè·ç¦»ç‚¹äº‘é…å‡†æ ·æœ¬ä¸‹åˆ·SOTAï¼ˆKITTIï¼š+40.9%; nuScenes: +26.9% -> reigistration recall)

> è®ºæ–‡ä¸­è¯´å¯¹æ¯”å­¦ä¹ æ–¹æ¡ˆè®¾è®¡æ›´å¤šè€ƒè™‘æ€ä¹ˆæå–æ›´åŠ å›°éš¾çš„è´Ÿæ ·æœ¬ï¼Œå¾ˆå°‘ç ”ç©¶æ€ä¹ˆæå‡æ­£æ ·æœ¬å¸¦æ¥çš„è®­ç»ƒæ•ˆæœ (A noticeable trend is that sampling more and harder negative samples will improve feature quality due to elevated stability and informativeness, but improvements on positive samples are scarce.)ï¼Œè™½ç„¶group contrastive learningä¸æ˜¯ä»€ä¹ˆæ–°æ¦‚å¿µï¼Œä½†æ˜¯æ®æˆ‘æµ…è–„çš„å­¦è¯†æ¥çœ‹ï¼Œç¡®å®æ˜¯ç¬¬ä¸€æ¬¡ç”¨åœ¨æœ¬æ–‡çš„ä»»åŠ¡ä¸Šã€‚

## Description

![image-20231005120314858](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224049425-207684440.png)

piplineè¿˜æ˜¯æ¯”è¾ƒæ¸…æ™°çš„å››ä¸ªæ­¥éª¤ï¼š

1. ä»¥ $C$ frameä¸ºä¸­å¿ƒï¼Œåœ¨ $[-60m, 60m]$ åŒºåŸŸå†…é€‰æ‹©Nä¸ªsegmentï¼Œå¹¶å¯¹segmentè¿›è¡Œå‡åŒ€é‡‡æ ·å¾—åˆ°ç‚¹äº‘(å¯¹äºè¿™ä¸ªé€‰æ‹©segmentæ–¹å¼æˆ‘è¿˜æ²¡æœ‰ç†æ¸…æ¥šğŸ˜­)ã€‚
2. ä½¿ç”¨fully convolutional features descriptor (FCGFã€KPConv)ä¸ºç‚¹äº‘ä¸­æ¯ä¸ªç‚¹æå–featureï¼›
3. ä½¿ç”¨nearest neighbor search ä»¥ $C$ ç‚¹äº‘æ¯ä¸ªç‚¹å¯»æ‰¾åœ¨å…¶ä»–ç‚¹äº‘ä¸‹çš„å¯¹åº”æ­£æ ·æœ¬ç‚¹ï¼Œå¹¶ä¸¢å¼ƒæ‰¾ä¸åˆ°å¤šä½™1ä¸ªå¯¹åº”ç‚¹çš„å‚è€ƒç‚¹ï¼Œç§°ä¸ºpositive group searchï¼›
4. ä¹‹åè®¡ç®—Group-wise Lossï¼š

$$
L = \lambda_1 L_{PV} + \lambda_2 L_{F} + \lambda_3 L_{HN}
$$

![image-20231005221641498](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224049901-64663823.png)

![image-20231005221755164](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224050283-2019822578.png)

![image-20231005221808735](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224050680-279266708.png)

-  $L_{PV}$ : positive variance loss( $\mu(Â·)$ is the average of all feature descriptors $f_x^i$ of $g_x$ correspondence group)
-  $L_F$ : Finest loss( $\mathcal{F}(Â·)$ is the finest feature for $g_x$ correspondence group)
-  $L_{HN}$ : the hardest negative loss

![image-20231005222352290](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224051181-590414909.png)

## Experiment

![image-20231005222825464](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224051923-2098013052.png)

å®è¯è¯´ï¼Œç¡®å®å‰å®³ï¼Œè¿™ä¸ªæç‚¹

## Ablation

å¯¹äºmulti positive point cloud setä¸­point cloudçš„æ•°ç›®ï¼š

![image-20231005223628991](https://img2023.cnblogs.com/blog/3251700/202310/3251700-20231005224052527-572819914.png)

å¯ä»¥çœ‹åˆ°å¾ˆæ˜æ˜¾ï¼Œå¢å¤šäº†æ­£æ ·æœ¬ç‚¹äº‘æ•°é‡ç¡®å®å¯¹äºæå–density-invariant featureå¾ˆæœ‰å¸®åŠ©ã€‚

[^1]: Saunshi, Nikunj, et al. "A theoretical analysis of contrastive unsupervised representation learning." *International Conference on Machine Learning*. PMLR, 2019.
